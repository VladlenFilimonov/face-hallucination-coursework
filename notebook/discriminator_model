digraph {
	graph [size="29.549999999999997,29.549999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2500317170960 [label="
 ()" fillcolor=darkolivegreen1]
	2500305300800 [label=MeanBackward0]
	2500305305504 -> 2500305300800
	2500305305504 [label=SigmoidBackward0]
	2500305291200 -> 2500305305504
	2500305291200 [label=ViewBackward0]
	2500305305952 -> 2500305291200
	2500305305952 [label=ConvolutionBackward0]
	2500305306384 -> 2500305305952
	2500305306384 [label=LeakyReluBackward0]
	2500305309984 -> 2500305306384
	2500305309984 [label=ConvolutionBackward0]
	2500305306096 -> 2500305309984
	2500305306096 [label=MeanBackward1]
	2500305250928 -> 2500305306096
	2500305250928 [label=LeakyReluBackward0]
	2500305363264 -> 2500305250928
	2500305363264 [label=NativeBatchNormBackward0]
	2500305363168 -> 2500305363264
	2500305363168 [label=ConvolutionBackward0]
	2500305362976 -> 2500305363168
	2500305362976 [label=LeakyReluBackward0]
	2500305362784 -> 2500305362976
	2500305362784 [label=NativeBatchNormBackward0]
	2500305362688 -> 2500305362784
	2500305362688 [label=ConvolutionBackward0]
	2500305362496 -> 2500305362688
	2500305362496 [label=LeakyReluBackward0]
	2500305362304 -> 2500305362496
	2500305362304 [label=NativeBatchNormBackward0]
	2500305362208 -> 2500305362304
	2500305362208 [label=ConvolutionBackward0]
	2500305362016 -> 2500305362208
	2500305362016 [label=LeakyReluBackward0]
	2500305361824 -> 2500305362016
	2500305361824 [label=NativeBatchNormBackward0]
	2500305361728 -> 2500305361824
	2500305361728 [label=ConvolutionBackward0]
	2500305361536 -> 2500305361728
	2500305361536 [label=LeakyReluBackward0]
	2500305361248 -> 2500305361536
	2500305361248 [label=NativeBatchNormBackward0]
	2500305361392 -> 2500305361248
	2500305361392 [label=ConvolutionBackward0]
	2500305360336 -> 2500305361392
	2500305360336 [label=LeakyReluBackward0]
	2500305360144 -> 2500305360336
	2500305360144 [label=NativeBatchNormBackward0]
	2500305360624 -> 2500305360144
	2500305360624 [label=ConvolutionBackward0]
	2500305360864 -> 2500305360624
	2500305360864 [label=LeakyReluBackward0]
	2500305364368 -> 2500305360864
	2500305364368 [label=NativeBatchNormBackward0]
	2500305363840 -> 2500305364368
	2500305363840 [label=ConvolutionBackward0]
	2500305363936 -> 2500305363840
	2500305363936 [label=LeakyReluBackward0]
	2500305360528 -> 2500305363936
	2500305360528 [label=ConvolutionBackward0]
	2500305357120 -> 2500305360528
	2500267687136 [label="net.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	2500267687136 -> 2500305357120
	2500305357120 [label=AccumulateGrad]
	2500305357312 -> 2500305360528
	2500267681856 [label="net.0.bias
 (64)" fillcolor=lightblue]
	2500267681856 -> 2500305357312
	2500305357312 [label=AccumulateGrad]
	2500305364176 -> 2500305363840
	2500267687056 [label="net.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2500267687056 -> 2500305364176
	2500305364176 [label=AccumulateGrad]
	2500305364224 -> 2500305363840
	2500267682336 [label="net.2.bias
 (64)" fillcolor=lightblue]
	2500267682336 -> 2500305364224
	2500305364224 [label=AccumulateGrad]
	2500305364320 -> 2500305364368
	2500267672576 [label="net.3.weight
 (64)" fillcolor=lightblue]
	2500267672576 -> 2500305364320
	2500305364320 [label=AccumulateGrad]
	2500305360768 -> 2500305364368
	2500267680896 [label="net.3.bias
 (64)" fillcolor=lightblue]
	2500267680896 -> 2500305360768
	2500305360768 [label=AccumulateGrad]
	2500305360912 -> 2500305360624
	2500267673536 [label="net.5.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2500267673536 -> 2500305360912
	2500305360912 [label=AccumulateGrad]
	2500305360960 -> 2500305360624
	2500267682576 [label="net.5.bias
 (128)" fillcolor=lightblue]
	2500267682576 -> 2500305360960
	2500305360960 [label=AccumulateGrad]
	2500305360576 -> 2500305360144
	2500267673056 [label="net.6.weight
 (128)" fillcolor=lightblue]
	2500267673056 -> 2500305360576
	2500305360576 [label=AccumulateGrad]
	2500305359904 -> 2500305360144
	2500267673616 [label="net.6.bias
 (128)" fillcolor=lightblue]
	2500267673616 -> 2500305359904
	2500305359904 [label=AccumulateGrad]
	2500305361104 -> 2500305361392
	2500127977568 [label="net.8.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2500127977568 -> 2500305361104
	2500305361104 [label=AccumulateGrad]
	2500305361152 -> 2500305361392
	2500127974528 [label="net.8.bias
 (128)" fillcolor=lightblue]
	2500127974528 -> 2500305361152
	2500305361152 [label=AccumulateGrad]
	2500305361344 -> 2500305361248
	2500316997376 [label="net.9.weight
 (128)" fillcolor=lightblue]
	2500316997376 -> 2500305361344
	2500305361344 [label=AccumulateGrad]
	2500305361440 -> 2500305361248
	2500316994976 [label="net.9.bias
 (128)" fillcolor=lightblue]
	2500316994976 -> 2500305361440
	2500305361440 [label=AccumulateGrad]
	2500305361584 -> 2500305361728
	2500316995136 [label="net.11.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2500316995136 -> 2500305361584
	2500305361584 [label=AccumulateGrad]
	2500305361632 -> 2500305361728
	2500316995536 [label="net.11.bias
 (256)" fillcolor=lightblue]
	2500316995536 -> 2500305361632
	2500305361632 [label=AccumulateGrad]
	2500305361776 -> 2500305361824
	2500316993536 [label="net.12.weight
 (256)" fillcolor=lightblue]
	2500316993536 -> 2500305361776
	2500305361776 [label=AccumulateGrad]
	2500305361920 -> 2500305361824
	2500316994096 [label="net.12.bias
 (256)" fillcolor=lightblue]
	2500316994096 -> 2500305361920
	2500305361920 [label=AccumulateGrad]
	2500305362064 -> 2500305362208
	2500316999136 [label="net.14.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2500316999136 -> 2500305362064
	2500305362064 [label=AccumulateGrad]
	2500305362112 -> 2500305362208
	2500317003696 [label="net.14.bias
 (256)" fillcolor=lightblue]
	2500317003696 -> 2500305362112
	2500305362112 [label=AccumulateGrad]
	2500305362256 -> 2500305362304
	2500316998256 [label="net.15.weight
 (256)" fillcolor=lightblue]
	2500316998256 -> 2500305362256
	2500305362256 [label=AccumulateGrad]
	2500305362400 -> 2500305362304
	2500316998336 [label="net.15.bias
 (256)" fillcolor=lightblue]
	2500316998336 -> 2500305362400
	2500305362400 [label=AccumulateGrad]
	2500305362544 -> 2500305362688
	2500316998576 [label="net.17.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2500316998576 -> 2500305362544
	2500305362544 [label=AccumulateGrad]
	2500305362592 -> 2500305362688
	2500317002656 [label="net.17.bias
 (512)" fillcolor=lightblue]
	2500317002656 -> 2500305362592
	2500305362592 [label=AccumulateGrad]
	2500305362736 -> 2500305362784
	2500317001936 [label="net.18.weight
 (512)" fillcolor=lightblue]
	2500317001936 -> 2500305362736
	2500305362736 [label=AccumulateGrad]
	2500305362880 -> 2500305362784
	2500317000096 [label="net.18.bias
 (512)" fillcolor=lightblue]
	2500317000096 -> 2500305362880
	2500305362880 [label=AccumulateGrad]
	2500305363024 -> 2500305363168
	2500316994256 [label="net.20.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2500316994256 -> 2500305363024
	2500305363024 [label=AccumulateGrad]
	2500305363072 -> 2500305363168
	2500317000256 [label="net.20.bias
 (512)" fillcolor=lightblue]
	2500317000256 -> 2500305363072
	2500305363072 [label=AccumulateGrad]
	2500305363216 -> 2500305363264
	2500316999216 [label="net.21.weight
 (512)" fillcolor=lightblue]
	2500316999216 -> 2500305363216
	2500305363216 [label=AccumulateGrad]
	2500305363360 -> 2500305363264
	2500316992816 [label="net.21.bias
 (512)" fillcolor=lightblue]
	2500316992816 -> 2500305363360
	2500305363360 [label=AccumulateGrad]
	2500305305760 -> 2500305309984
	2500316990816 [label="net.24.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2500316990816 -> 2500305305760
	2500305305760 [label=AccumulateGrad]
	2500307770848 -> 2500305309984
	2500316989536 [label="net.24.bias
 (1024)" fillcolor=lightblue]
	2500316989536 -> 2500307770848
	2500307770848 [label=AccumulateGrad]
	2500305306144 -> 2500305305952
	2500316989376 [label="net.26.weight
 (1, 1024, 1, 1)" fillcolor=lightblue]
	2500316989376 -> 2500305306144
	2500305306144 [label=AccumulateGrad]
	2500305306672 -> 2500305305952
	2500316989776 [label="net.26.bias
 (1)" fillcolor=lightblue]
	2500316989776 -> 2500305306672
	2500305306672 [label=AccumulateGrad]
	2500305300800 -> 2500317170960
}
